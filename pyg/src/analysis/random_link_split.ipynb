{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.data.storage import EdgeStorage\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.typing import EdgeType\n",
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functional_transform(\"random_link_split\")\n",
    "class RandomLinkSplit(BaseTransform):\n",
    "    r\"\"\"Performs an edge-level random split into training, validation and test\n",
    "    sets of a :class:`~torch_geometric.data.Data` or a\n",
    "    :class:`~torch_geometric.data.HeteroData` object\n",
    "    (functional name: :obj:`random_link_split`).\n",
    "    The split is performed such that the training split does not include edges\n",
    "    in validation and test splits; and the validation split does not include\n",
    "    edges in the test split.\n",
    "\n",
    "    .. code-block::\n",
    "\n",
    "        from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "        transform = RandomLinkSplit(is_undirected=True)\n",
    "        train_data, val_data, test_data = transform(data)\n",
    "\n",
    "    Args:\n",
    "        num_val (int or float, optional): The number of validation edges.\n",
    "            If set to a floating-point value in :math:`[0, 1]`, it represents\n",
    "            the ratio of edges to include in the validation set.\n",
    "            (default: :obj:`0.1`)\n",
    "        num_test (int or float, optional): The number of test edges.\n",
    "            If set to a floating-point value in :math:`[0, 1]`, it represents\n",
    "            the ratio of edges to include in the test set.\n",
    "            (default: :obj:`0.2`)\n",
    "        is_undirected (bool): If set to :obj:`True`, the graph is assumed to be\n",
    "            undirected, and positive and negative samples will not leak\n",
    "            (reverse) edge connectivity across different splits. This only\n",
    "            affects the graph split, label data will not be returned\n",
    "            undirected. This option is ignored for bipartite edge types or\n",
    "            whenever :obj:`edge_type != rev_edge_type`. (default: :obj:`False`)\n",
    "        key (str, optional): The name of the attribute holding\n",
    "            ground-truth labels.\n",
    "            If :obj:`data[key]` does not exist, it will be automatically\n",
    "            created and represents a binary classification task\n",
    "            (:obj:`1` = edge, :obj:`0` = no edge).\n",
    "            If :obj:`data[key]` exists, it has to be a categorical label from\n",
    "            :obj:`0` to :obj:`num_classes - 1`.\n",
    "            After negative sampling, label :obj:`0` represents negative edges,\n",
    "            and labels :obj:`1` to :obj:`num_classes` represent the labels of\n",
    "            positive edges. (default: :obj:`\"edge_label\"`)\n",
    "        split_labels (bool, optional): If set to :obj:`True`, will split\n",
    "            positive and negative labels and save them in distinct attributes\n",
    "            :obj:`\"pos_edge_label\"` and :obj:`\"neg_edge_label\"`, respectively.\n",
    "            (default: :obj:`False`)\n",
    "        add_negative_train_samples (bool, optional): Whether to add negative\n",
    "            training samples for link prediction.\n",
    "            If the model already performs negative sampling, then the option\n",
    "            should be set to :obj:`False`.\n",
    "            Otherwise, the added negative samples will be the same across\n",
    "            training iterations unless negative sampling is performed again.\n",
    "            (default: :obj:`True`)\n",
    "        neg_sampling_ratio (float, optional): The ratio of sampled negative\n",
    "            edges to the number of positive edges. (default: :obj:`1.0`)\n",
    "        disjoint_train_ratio (int or float, optional): If set to a value\n",
    "            greater than :obj:`0.0`, training edges will not be shared for\n",
    "            message passing and supervision. Instead,\n",
    "            :obj:`disjoint_train_ratio` edges are used as ground-truth labels\n",
    "            for supervision during training. (default: :obj:`0.0`)\n",
    "        edge_types (Tuple[EdgeType] or List[EdgeType], optional): The edge\n",
    "            types used for performing edge-level splitting in case of\n",
    "            operating on :class:`~torch_geometric.data.HeteroData` objects.\n",
    "            (default: :obj:`None`)\n",
    "        rev_edge_types (Tuple[EdgeType] or List[Tuple[EdgeType]], optional):\n",
    "            The reverse edge types of :obj:`edge_types` in case of operating\n",
    "            on :class:`~torch_geometric.data.HeteroData` objects.\n",
    "            This will ensure that edges of the reverse direction will be\n",
    "            split accordingly to prevent any data leakage.\n",
    "            Can be :obj:`None` in case no reverse connection exists.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_val: Union[int, float] = 0.1,\n",
    "        num_test: Union[int, float] = 0.2,\n",
    "        is_undirected: bool = False,\n",
    "        key: str = \"edge_label\",\n",
    "        split_labels: bool = False,\n",
    "        add_negative_train_samples: bool = True,\n",
    "        neg_sampling_ratio: float = 1.0,\n",
    "        disjoint_train_ratio: Union[int, float] = 0.0,\n",
    "        edge_types: Optional[Union[EdgeType, List[EdgeType]]] = None,\n",
    "        rev_edge_types: Optional[\n",
    "            Union[\n",
    "                EdgeType,\n",
    "                List[Optional[EdgeType]],\n",
    "            ]\n",
    "        ] = None,\n",
    "    ) -> None:\n",
    "        if isinstance(edge_types, list):\n",
    "            if rev_edge_types is None:\n",
    "                rev_edge_types = [None] * len(edge_types)\n",
    "\n",
    "            assert isinstance(rev_edge_types, list)\n",
    "            assert len(edge_types) == len(rev_edge_types)\n",
    "\n",
    "        self.num_val = num_val\n",
    "        self.num_test = num_test\n",
    "        self.is_undirected = is_undirected\n",
    "        self.key = key\n",
    "        self.split_labels = split_labels\n",
    "        self.add_negative_train_samples = add_negative_train_samples\n",
    "        self.neg_sampling_ratio = neg_sampling_ratio\n",
    "        self.disjoint_train_ratio = disjoint_train_ratio\n",
    "        self.edge_types = edge_types\n",
    "        self.rev_edge_types = rev_edge_types\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data: Union[Data, HeteroData],\n",
    "    ) -> Tuple[\n",
    "        Union[Data, HeteroData],\n",
    "        Union[Data, HeteroData],\n",
    "        Union[Data, HeteroData],\n",
    "    ]:\n",
    "        edge_types = self.edge_types\n",
    "        rev_edge_types = self.rev_edge_types\n",
    "\n",
    "        train_data = copy.copy(data)\n",
    "        val_data = copy.copy(data)\n",
    "        test_data = copy.copy(data)\n",
    "\n",
    "        if isinstance(data, HeteroData):\n",
    "            assert isinstance(train_data, HeteroData)\n",
    "            assert isinstance(val_data, HeteroData)\n",
    "            assert isinstance(test_data, HeteroData)\n",
    "\n",
    "            if edge_types is None:\n",
    "                raise ValueError(\n",
    "                    \"The 'RandomLinkSplit' transform expects 'edge_types' to \"\n",
    "                    \"be specified when operating on 'HeteroData' objects\"\n",
    "                )\n",
    "\n",
    "            if not isinstance(edge_types, list):\n",
    "                assert not isinstance(rev_edge_types, list)\n",
    "                edge_types = [edge_types]\n",
    "                rev_edge_types = [rev_edge_types]\n",
    "\n",
    "            stores = [data[edge_type] for edge_type in edge_types]\n",
    "            train_stores = [train_data[edge_type] for edge_type in edge_types]\n",
    "            val_stores = [val_data[edge_type] for edge_type in edge_types]\n",
    "            test_stores = [test_data[edge_type] for edge_type in edge_types]\n",
    "        else:\n",
    "            assert isinstance(train_data, Data)\n",
    "            assert isinstance(val_data, Data)\n",
    "            assert isinstance(test_data, Data)\n",
    "\n",
    "            rev_edge_types = [None]\n",
    "\n",
    "            train_data = copy.copy(data)\n",
    "            val_data = copy.copy(data)\n",
    "            test_data = copy.copy(data)\n",
    "\n",
    "            stores = [data._store]\n",
    "            train_stores = [train_data._store]\n",
    "            val_stores = [val_data._store]\n",
    "            test_stores = [test_data._store]\n",
    "\n",
    "        assert isinstance(rev_edge_types, list)\n",
    "        for item in zip(stores, train_stores, val_stores, test_stores, rev_edge_types):\n",
    "            store, train_store, val_store, test_store, rev_edge_type = item\n",
    "\n",
    "            is_undirected = self.is_undirected\n",
    "            is_undirected &= not store.is_bipartite()\n",
    "            is_undirected &= rev_edge_type is None or (\n",
    "                isinstance(data, HeteroData) and store._key == data[rev_edge_type]._key\n",
    "            )\n",
    "\n",
    "            edge_index = store.edge_index\n",
    "            if is_undirected:\n",
    "                mask = edge_index[0] <= edge_index[1]\n",
    "                perm = mask.nonzero(as_tuple=False).view(-1)\n",
    "                perm = perm[torch.randperm(perm.size(0), device=perm.device)]\n",
    "            else:\n",
    "                device = edge_index.device\n",
    "                perm = torch.randperm(edge_index.size(1), device=device)\n",
    "\n",
    "            num_val = self.num_val\n",
    "            if isinstance(num_val, float):\n",
    "                num_val = int(num_val * perm.numel())\n",
    "            num_test = self.num_test\n",
    "            if isinstance(num_test, float):\n",
    "                num_test = int(num_test * perm.numel())\n",
    "\n",
    "            num_train = perm.numel() - num_val - num_test\n",
    "\n",
    "            if num_train <= 0:\n",
    "                raise ValueError(\"Insufficient number of edges for training\")\n",
    "\n",
    "            train_edges = perm[:num_train]\n",
    "            val_edges = perm[num_train : num_train + num_val]\n",
    "            test_edges = perm[num_train + num_val :]\n",
    "            train_val_edges = perm[: num_train + num_val]\n",
    "\n",
    "            num_disjoint = self.disjoint_train_ratio\n",
    "            if isinstance(num_disjoint, float):\n",
    "                num_disjoint = int(num_disjoint * train_edges.numel())\n",
    "            if num_train - num_disjoint <= 0:\n",
    "                raise ValueError(\"Insufficient number of edges for training\")\n",
    "\n",
    "            # Create data splits:\n",
    "            self._split(\n",
    "                train_store, train_edges[num_disjoint:], is_undirected, rev_edge_type\n",
    "            )\n",
    "            self._split(val_store, train_edges, is_undirected, rev_edge_type)\n",
    "            self._split(test_store, train_val_edges, is_undirected, rev_edge_type)\n",
    "\n",
    "            # Create negative samples:\n",
    "            num_neg_train = 0\n",
    "            if self.add_negative_train_samples:\n",
    "                if num_disjoint > 0:\n",
    "                    num_neg_train = int(num_disjoint * self.neg_sampling_ratio)\n",
    "                else:\n",
    "                    num_neg_train = int(num_train * self.neg_sampling_ratio)\n",
    "            num_neg_val = int(num_val * self.neg_sampling_ratio)\n",
    "            num_neg_test = int(num_test * self.neg_sampling_ratio)\n",
    "\n",
    "            num_neg = num_neg_train + num_neg_val + num_neg_test\n",
    "\n",
    "            size = store.size()\n",
    "            if store._key is None or store._key[0] == store._key[-1]:\n",
    "                size = size[0]\n",
    "            neg_edge_index = negative_sampling(\n",
    "                edge_index, size, num_neg_samples=num_neg, method=\"sparse\"\n",
    "            )\n",
    "\n",
    "            # Adjust ratio if not enough negative edges exist\n",
    "            if neg_edge_index.size(1) < num_neg:\n",
    "                num_neg_found = neg_edge_index.size(1)\n",
    "                ratio = num_neg_found / num_neg\n",
    "                warnings.warn(\n",
    "                    f\"There are not enough negative edges to satisfy \"\n",
    "                    \"the provided sampling ratio. The ratio will be \"\n",
    "                    f\"adjusted to {ratio:.2f}.\"\n",
    "                )\n",
    "                num_neg_train = int((num_neg_train / num_neg) * num_neg_found)\n",
    "                num_neg_val = int((num_neg_val / num_neg) * num_neg_found)\n",
    "                num_neg_test = num_neg_found - num_neg_train - num_neg_val\n",
    "\n",
    "            # Create labels:\n",
    "            if num_disjoint > 0:\n",
    "                train_edges = train_edges[:num_disjoint]\n",
    "            self._create_label(\n",
    "                store,\n",
    "                train_edges,\n",
    "                neg_edge_index[:, num_neg_val + num_neg_test :],\n",
    "                out=train_store,\n",
    "            )\n",
    "            self._create_label(\n",
    "                store,\n",
    "                val_edges,\n",
    "                neg_edge_index[:, :num_neg_val],\n",
    "                out=val_store,\n",
    "            )\n",
    "            self._create_label(\n",
    "                store,\n",
    "                test_edges,\n",
    "                neg_edge_index[:, num_neg_val : num_neg_val + num_neg_test],\n",
    "                out=test_store,\n",
    "            )\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    def _split(\n",
    "        self,\n",
    "        store: EdgeStorage,\n",
    "        index: Tensor,\n",
    "        is_undirected: bool,\n",
    "        rev_edge_type: Optional[EdgeType],\n",
    "    ) -> EdgeStorage:\n",
    "        edge_attrs = {key for key in store.keys() if store.is_edge_attr(key)}\n",
    "        for key, value in store.items():\n",
    "            if key == \"edge_index\":\n",
    "                continue\n",
    "\n",
    "            if key in edge_attrs:\n",
    "                value = value[index]\n",
    "                if is_undirected:\n",
    "                    value = torch.cat([value, value], dim=0)\n",
    "                store[key] = value\n",
    "\n",
    "        edge_index = store.edge_index[:, index]\n",
    "        if is_undirected:\n",
    "            edge_index = torch.cat([edge_index, edge_index.flip([0])], dim=-1)\n",
    "        store.edge_index = edge_index\n",
    "\n",
    "        if rev_edge_type is not None:\n",
    "            rev_store = store._parent()[rev_edge_type]\n",
    "            for key in rev_store.keys():\n",
    "                if key not in store:\n",
    "                    del rev_store[key]  # We delete all outdated attributes.\n",
    "                elif key == \"edge_index\":\n",
    "                    rev_store.edge_index = store.edge_index.flip([0])\n",
    "                else:\n",
    "                    rev_store[key] = store[key]\n",
    "\n",
    "        return store\n",
    "\n",
    "    def _create_label(\n",
    "        self,\n",
    "        store: EdgeStorage,\n",
    "        index: Tensor,\n",
    "        neg_edge_index: Tensor,\n",
    "        out: EdgeStorage,\n",
    "    ) -> EdgeStorage:\n",
    "        edge_index = store.edge_index[:, index]\n",
    "\n",
    "        if hasattr(store, self.key):\n",
    "            edge_label = store[self.key]\n",
    "            edge_label = edge_label[index]\n",
    "            # Increment labels by one. Note that there is no need to increment\n",
    "            # in case no negative edges are added.\n",
    "            if neg_edge_index.numel() > 0:\n",
    "                assert edge_label.dtype == torch.long\n",
    "                assert edge_label.size(0) == edge_index.size(1)\n",
    "                edge_label.add_(1)\n",
    "            if hasattr(out, self.key):\n",
    "                delattr(out, self.key)\n",
    "        else:\n",
    "            edge_label = torch.ones(index.numel(), device=index.device)\n",
    "\n",
    "        if neg_edge_index.numel() > 0:\n",
    "            neg_edge_label = edge_label.new_zeros(\n",
    "                (neg_edge_index.size(1),) + edge_label.size()[1:]\n",
    "            )\n",
    "\n",
    "        if self.split_labels:\n",
    "            out[f\"pos_{self.key}\"] = edge_label\n",
    "            out[f\"pos_{self.key}_index\"] = edge_index\n",
    "            if neg_edge_index.numel() > 0:\n",
    "                out[f\"neg_{self.key}\"] = neg_edge_label\n",
    "                out[f\"neg_{self.key}_index\"] = neg_edge_index\n",
    "\n",
    "        else:\n",
    "            if neg_edge_index.numel() > 0:\n",
    "                edge_label = torch.cat([edge_label, neg_edge_label], dim=0)\n",
    "                edge_index = torch.cat([edge_index, neg_edge_index], dim=-1)\n",
    "            out[self.key] = edge_label\n",
    "            out[f\"{self.key}_index\"] = edge_index\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(num_val={self.num_val}, \"\n",
    "            f\"num_test={self.num_test})\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
